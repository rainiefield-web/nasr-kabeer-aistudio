import os
import time
import json
import re
import traceback

try:
    from google import genai
    from google.genai import types
except ImportError as e:
    print(f"ImportError: {e}. è¯·ç¡®ä¿å®‰è£…äº† google-genai åº“ã€‚")
    exit(1)

def extract_json_payload(text):
    """
    æè‡´å®¹é”™ç‰ˆè§£æå™¨ï¼š
    1. ç§»é™¤ Markdown æ ‡ç­¾å’Œæœç´¢å¼•ç”¨ã€‚
    2. è§£ææ–‡æœ¬ä¸­çš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆ JSON å¯¹è±¡ã€‚
    3. å¤„ç† JSON å†…éƒ¨çš„éæ³•æ¢è¡Œå’Œå¤šä½™é€—å·ã€‚
    """
    if not text:
        return None
    
    # é¢„æ¸…æ´—ï¼šå‰¥ç¦» Markdown ç¬¦å·å’Œæœç´¢æ¥æºå¼•ç”¨ [1], [2] ç­‰
    cleaned = text.replace("```json", "").replace("```", "")
    cleaned = re.sub(r'\[\d+\]', '', cleaned)
    cleaned = cleaned.strip()

    # æ ¸å¿ƒæå–ï¼šä½¿ç”¨ JSONDecoder æŠ½å–ç¬¬ä¸€ä¸ªå®Œæ•´å¯¹è±¡
    decoder = json.JSONDecoder()
    start = cleaned.find("{")
    while start != -1 and start < len(cleaned):
        try:
            obj, _ = decoder.raw_decode(cleaned[start:])
            return obj
        except json.JSONDecodeError:
            start = cleaned.find("{", start + 1)

    # å…œåº•ï¼šç®€å•æ­£åˆ™ä¿®å¤
    try:
        start = cleaned.find("{")
        end = cleaned.rfind("}")
        if start != -1 and end != -1:
            json_str = cleaned[start:end + 1]
            sanitized_str = re.sub(r'\n\s*', ' ', json_str)
            sanitized_str = re.sub(r',\s*([\]}])', r'\1', sanitized_str)
            return json.loads(sanitized_str)
    except:
        return None
    return None

def main():
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("Error: GEMINI_API_KEY is not set.")
        exit(1)

    client = genai.Client(api_key=api_key)
    
    # ä¼˜åŒ– Promptï¼šå¼ºè°ƒâ€œæœ€å¤§åŒ–è·å–â€ï¼Œå¹¶æ˜ç¡® LME æ ¼å¼
    prompt = """
    Search for TODAY'S real, verifiable global aluminum industry news and market data.
    
    Target Sources:
    - https://www.aluminium-journal.com/news
    - https://www.investing.com/commodities/aluminum-news
    - https://aluminiumtoday.com/news
    - https://news.metal.com/list/latest/aluminium

    Requirements:
    1. LME: Find the latest LME Aluminum Cash Price and daily % change. 
    2. CONTENT: Extract real corporate moves (Alcoa, Rio Tinto, Emirates Global Aluminium, etc.), trends, and strategic factors.
    3. NO PLACEHOLDERS: Do not use "Company A" or "Project X". If a specific name isn't found, describe the event accurately.
    4. LINKS: Every news bullet MUST include a source URL (https://...).
    5. TRANSLATION: Translate every English point into professional Arabic in the 'ar' section.

    Structure (STRICT JSON):
    {
      "date": "YYYY-MM-DD",
      "en": { "lme": [], "corporate": [], "trends": [], "factors": [] },
      "ar": { "lme": [], "corporate": [], "trends": [], "factors": [] }
    }
    """

    try:
        # ä½¿ç”¨ Gemini 2.0 Flash è·å–å®æ—¶æ•°æ®
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                tools=[types.Tool(google_search=types.GoogleSearch())]
            )
        )

        text_content = response.text if response.text else ""
        data = extract_json_payload(text_content)

        if not data:
            print("Error: Failed to extract a valid JSON object from API response.")
            exit(1)

        # --- ä¼˜åŒ–åçš„æ ¡éªŒä¸æ¸…æ´—é€»è¾‘ ---
        required_sections = ["lme", "corporate", "trends", "factors"]
        valid_content_found = False
        url_pattern = re.compile(r"https?://\S+")

        for lang in ["en", "ar"]:
            if lang not in data: data[lang] = {}
            for section in required_sections:
                entries = data[lang].get(section, [])
                
                # å®¹é”™ï¼šå¦‚æœ API è¿”å›çš„ä¸æ˜¯åˆ—è¡¨ï¼ˆå¦‚å­—ç¬¦ä¸²ï¼‰ï¼Œå¼ºè½¬åˆ—è¡¨
                if not isinstance(entries, list):
                    entries = [str(entries)] if entries else []
                
                # æ¸…æ´—æ¡ç›®ï¼šè¿‡æ»¤æ‰æ— æ•ˆå ä½ç¬¦ï¼Œä¿ç•™æœ‰å†…å®¹çš„é¡¹
                cleaned = []
                for item in entries:
                    item_str = str(item)
                    # è¿‡æ»¤æ‰æ˜æ˜¾çš„è™šå‡å ä½ç¬¦
                    if "Company A" in item_str or "placeholder" in item_str.lower():
                        continue
                    if len(item_str) > 10:  # é•¿åº¦è¿‡æ»¤ï¼Œç¡®ä¿ä¸æ˜¯ç©ºè¯
                        cleaned.append(item_str)
                        valid_content_found = True
                
                data[lang][section] = cleaned

        # ç‰¹æ®Šæ£€æŸ¥ï¼šLME æ•°æ®é¢„è­¦ä½†ä¸ä¸­æ–­
        lme_entries = data.get("en", {}).get("lme", [])
        if not any(re.search(r"\d", str(e)) for e in lme_entries):
            print("Warning: No numeric LME price found. Proceeding with other news.")

        if not valid_content_found:
            print("Warning: No valid industry news entries found. Skipping file update to avoid empty reports.")
            exit(0)

        # æ ¡éªŒæ—¥æœŸ
        if not data.get("date") or "YYYY" in str(data["date"]):
            data["date"] = time.strftime('%Y-%m-%d')

        # --- æ–‡ä»¶ä¿å­˜é€»è¾‘ ---
        base_dir = os.path.dirname(os.path.abspath(__file__))
        public_dir = os.path.join(base_dir, "public")
        os.makedirs(public_dir, exist_ok=True)

        # 1. ä¿å­˜ JSON
        json_path = os.path.join(public_dir, "news_data.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        # 2. ç”Ÿæˆ Markdown æŠ¥å‘Š
        updated_at = time.strftime('%Y-%m-%d %H:%M:%S')
        md_lines = [
            f"# Aluminum Industry News Summary ({data['date']})",
            f"Last Updated: {updated_at} UTC",
            "\n> *This report is automatically generated using Gemini 2.0 Flash with real-time web search.*",
            "",
            "## ğŸŒ English Analysis",
        ]
        
        section_map = [
            ("lme", "ğŸ“ˆ LME Price & Market"),
            ("corporate", "ğŸ¢ Corporate Updates"), 
            ("trends", "ğŸ“Š Industry Trends"), 
            ("factors", "ğŸ’¡ Strategic Factors")
        ]

        for key, title in section_map:
            md_lines.append(f"### {title}")
            items = data["en"].get(key, [])
            if not items:
                md_lines.append("- No major updates found in this category for today.")
            else:
                for item in items:
                    md_lines.append(f"- {item}")
            md_lines.append("")

        md_lines.append("---")
        md_lines.append("## ğŸŒ Arabic Summary (Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ)")
        
        ar_section_map = [
            ("lme", "ØªØ­Ù„ÙŠÙ„ Ø¨ÙˆØ±ØµØ© Ù„Ù†Ø¯Ù† (LME)"),
            ("corporate", "ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ§Øª"), 
            ("trends", "ØªÙˆØ¬Ù‡Ø§Øª Ø§Ù„ØµÙ†Ø§Ø¹Ø©"), 
            ("factors", "Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©")
        ]
        
        for key, title in ar_section_map:
            md_lines.append(f"### {title}")
            items = data["ar"].get(key, [])
            if not items:
                md_lines.append("- Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ÙŠÙˆÙ….")
            else:
                for item in items:
                    md_lines.append(f"- {item}")
            md_lines.append("")

        # å†™å…¥ä¸¤ä¸ªä½ç½®ç¡®ä¿åŒæ­¥
        targets = [
            os.path.join(base_dir, "aluminum_industry_news.md"),
            os.path.join(public_dir, "aluminum_industry_news.md")
        ]
        for target in targets:
            with open(target, "w", encoding="utf-8") as f:
                f.write("\n".join(md_lines))
        
        print(f"Successfully updated news for {data['date']}.")

    except Exception as e:
        if "429" in str(e):
            print("Status: QUOTA_EXHAUSTED. Gemini Free tier limit reached. Please try again later.")
            exit(0)
        else:
            traceback.print_exc()
            exit(1)

if __name__ == "__main__":
    main()
