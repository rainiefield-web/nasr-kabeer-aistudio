import os
import time
import json
import re
import traceback
import requests
from datetime import datetime, timedelta

try:
    from google import genai
    from google.genai import types
except ImportError as e:
    print(f"ImportError: {e}")
    exit(1)

# --- æ ¸å¿ƒé…ç½® (æ–°å¢äº† NEWSAPI_DOMAINS) ---
MIN_PRICE_THRESHOLD = 2700.0
CORE_SITES = "Reuters, Bloomberg, Fastmarkets, AlCircle, Aluminium Insider, Mining.com, S&P Global"

# --- OPTIMIZATION 1: é™å®š NewsAPI çš„æœç´¢èŒƒå›´ ---
# åªåœ¨è¿™äº›æƒå¨çš„ã€ä¸è¡Œä¸šç›¸å…³çš„åŸŸåä¸‹æœç´¢ï¼Œä»æ ¹æºä¸Šè¿‡æ»¤å™ªéŸ³
NEWSAPI_DOMAINS = "reuters.com,bloomberg.com,fastmarkets.com,alcircle.com,aluminiuminsider.com,mining.com,spglobal.com"

# --- NewsAPI ä¸“å±å‡½æ•° (å·²å‡çº§) ---
def fetch_news_from_api(query: str, domains: str, language: str = 'en', page_size: int = 10):
    """
    ä½¿ç”¨ NewsAPI ç›´æ¥è·å–æ–°é—»ï¼Œå¢åŠ äº† domains å’Œ searchIn=title å‚æ•°ä»¥æé«˜ç²¾åº¦ã€‚
    """
    api_key = os.getenv("NEWS_API_KEY")
    if not api_key:
        print("è­¦å‘Šï¼šNEWS_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ NewsAPI çš„æ–°é—»è·å–ã€‚")
        return []

    # --- OPTIMIZATION 2: æ„å»ºæ›´ç²¾å‡†çš„è¯·æ±‚ URL ---
    url = (f"https://newsapi.org/v2/everything?"
           f"qInTitle={query}&"  # å¼ºåˆ¶åœ¨æ ‡é¢˜ä¸­æœç´¢å…³é”®è¯
           f"domains={domains}&"      # åªæœç´¢æŒ‡å®šçš„åŸŸå
           f"language={language}&"
           f"sortBy=publishedAt&"
           f"pageSize={page_size}&"
           f"apiKey={api_key}")

    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        
        # å¢åŠ ä¸€ä¸ªå¥å…¨æ€§æ£€æŸ¥ï¼Œä»¥é˜²è¿”å›ç©ºçš„æ–‡ç« åˆ—è¡¨
        articles = data.get('articles', [])
        if not articles:
            print(f"NewsAPI åœ¨æŒ‡å®šåŸŸå {domains} æœªæ‰¾åˆ°å…³äº '{query}' çš„æ–°é—»ã€‚")
        return articles

    except requests.exceptions.RequestException as e:
        print(f"ä» NewsAPI è¯·æ±‚æ–°é—»æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

# --- Gemini AI åŠå…¶ä»–è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) ---
def clean_text(text):
    if not text: return ""
    text = text.replace("\\\\", "")
    text = re.sub(r"\\\[\\d+\\\]", "", text)
    text = re.sub(r"hypothetical\\S+", "", text)
    return text.strip()

def extract_json(text):
    if not text: return None
    cleaned = text.replace("\`\`\`json", "").replace("\`\`\`", "").strip()
    start = cleaned.find("{")
    while start != -1:
        try:
            return json.JSONDecoder().raw_decode(cleaned[start:])[0]
        except:
            start = cleaned.find("{", start + 1)
    return None

def fetch_content_from_genai(client, prompt):
    for model_name in ["gemini-1.5-flash", "gemini-1.5-pro"]:
        try:
            response = client.models.generate_content(
                model=model_name,
                contents=prompt,
                generation_config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                ),
                tools=[types.Tool(google_search=types.GoogleSearch())]
            )
            data = extract_json(response.text)
            if data: return data
        except Exception as e:
            print(f"ä½¿ç”¨æ¨¡å‹ {model_name} æ—¶å‡ºé”™: {e}")
            continue
    return None

def main():
    gemini_api_key = os.environ.get("GEMINI_API_KEY")
    if not gemini_api_key:
        print("é”™è¯¯ï¼šGEMINI_API_KEY æœªè®¾ç½®ã€‚ç¨‹åºé€€å‡ºã€‚")
        exit(1)
    
    client = genai.Client(api_key=gemini_api_key)

    now = datetime.utcnow()
    current_time_utc = now.strftime('%Y-%m-%d %H:%M:%S')

    # --- ä»»åŠ¡ prompts (ä¿æŒä¸å˜) ---
    lme_prompt = f"Get LME Primary Aluminum (High Grade) Cash Settlement Price from the last 4 hours. Strict: Price must be over $2700. Source: Prefer Investing.com, Fastmarkets, or Reuters. Output JSON: {{ \"en\": {{ \"lme\": [{{ \"price\": \"$xxxx.xx\", \"change\": \"Â±x.x%\", \"date\": \"YYYY-MM-DD\" }}] }} }}"
    
    news_prompt = f"""
    Deep scan English-language aluminum industry news from these portals: {CORE_SITES}.
    Language Requirement: Must be in English.
    Focus: Smelter production, Bauxite supply, ESG, Automotive demand.
    Extract 8 high-quality news bullets. Use REAL URLs.
    Output JSON: {{ "en": {{ "corporate": [], "trends": [], "factors": [] }} }}
    """
    
    # --- API è°ƒç”¨ (å·²ä½¿ç”¨æ–°çš„ä¼˜åŒ–ç­–ç•¥) ---
    print("æ­£åœ¨ä» NewsAPI çš„æŒ‡å®šåŸŸåä¸­ï¼Œç²¾ç¡®è·å–æœ€æ–°è‹±æ–‡æ–°é—»...")
    newsapi_articles = fetch_news_from_api(
        query="aluminum OR aluminium", # å…³é”®è¯ç°åœ¨å¯ä»¥åœ¨æ ‡é¢˜ä¸­æŸ¥æ‰¾
        domains=NEWSAPI_DOMAINS,       # ä¼ å…¥æˆ‘ä»¬é™å®šçš„åŸŸååˆ—è¡¨
        page_size=8
    )
    
    print("æ­£åœ¨é€šè¿‡ Gemini è·å–ä»·æ ¼å’Œæ·±åº¦æ–°é—»...")
    lme_data = fetch_content_from_genai(client, lme_prompt)
    news_data = fetch_content_from_genai(client, news_prompt)

    # --- æ•°æ®æ•´åˆä¸æ¸²æŸ“ (ä¿æŒä¸å˜) ---
    valid_lme = []
    if lme_data and "en" in lme_data and "lme" in lme_data["en"]:
        for entry in lme_data["en"]["lme"]:
            try:
                p_val = float(str(entry.get("price")).replace("$", "").replace(",", ""))
                if p_val >= MIN_PRICE_THRESHOLD: valid_lme.append(entry)
            except: continue

    final_data = {
        "date": now.strftime('%Y-%m-%d'),
        "en": { "lme": valid_lme, "newsapi_headlines": newsapi_articles, "corporate": [], "trends": [], "factors": [] },
    }

    if news_data and "en" in news_data:
        for sec in ["corporate", "trends", "factors"]:
            raw_items = news_data["en"].get(sec, [])
            final_data["en"][sec] = [{"bullet": clean_text(i.get("bullet","")), "url": i.get("url","")} for i in raw_items if i.get("bullet") and "hypothetical" not in str(i.get("url")).lower()]

    def render_md(data):
        lines = [f"# ğŸ› ï¸ Aluminum Global Intelligence Report", f"**Last Updated:** `{current_time_utc} UTC`", f"**Status:** ğŸŸ¢ Data Integrity Verified", ""]
        lines.append("## Global English Report")
        sections = [("lme", "ğŸ’° LME Primary Aluminum Data"), ("newsapi_headlines", "âš¡ï¸ Latest Headlines (from NewsAPI)"), ("corporate", "ğŸ¢ Industry & Corporate Insights (from Gemini)"), ("trends", "ğŸ“Š Market Trends (from Gemini)"), ("factors", "ğŸŒ Strategic Factors (from Gemini)")]
        for key, sec_title in sections:
            items = data["en"].get(key, [])
            if not items: continue
            lines.append(f"### {sec_title}")
            for item in items:
                if key == "lme": lines.append(f"> **LME Cash:** `{item.get('price')}` | **Change:** `{item.get('change')}` | **Ref Date:** {item.get('date')}")
                elif key == "newsapi_headlines":
                    source_name = item.get('source', {}).get('name', 'N/A')
                    lines.append(f"- {item.get('title')} (*Source: {source_name}*) [ğŸ”— Link]({item.get('url')})")
                else:
                    url = item.get('url')
                    lines.append(f"- {item.get('bullet')} [ğŸ”— Source]({url})" if url and "http" in url else f"- {item.get('bullet')}")
            lines.append("")
        return "\n".join(lines)

    content = render_md(final_data)
    base_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else os.getcwd()
    output_path = os.path.join(base_dir, "aluminum_industry_news.md")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f: f.write(content)
    print(f"æŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆ: {output_path}")

if __name__ == "__main__":
    main()
